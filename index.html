<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- Hi, Jon Here. Please DELETE the two <script> tags below if you use this HTML, otherwise my analytics will track your page -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-7580334-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-7580334-2');
  </script>

  <title>Ziwei Wang</title>
  
  <meta name="author" content="Ziwei Wang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/icon.png">
</head>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-6EJMX75K3R"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-6EJMX75K3R');
</script>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Ziwei Wang</name>
              </p>
              <p>Ziwei Wang is currently an assistant professor in School of Electrical and Electronic Engineering, Nanyang Technological University and the director of <a href="https://pine-lab-ntu.github.io"><strong>P</strong>erception and embodied <strong>IN</strong>t<strong>E</strong>lligence (<strong>PINE</strong>) Lab</a>. Before joining NTU, he was a postdoc fellow in Robotics Institute, Carnegie Mellon University, with Prof. Changliu Liu. He received the Ph.D and the B.S degrees from the Department of Automation, Tsinghua University in 2023 and the Department of Physics, Tsinghua University in 2018 respectively.
                 His research goal is to design foundation models (FMs) for robotic manipulation. He has published over 40 scientific papers in TPAMI, IJCV, RAL, CVPR, ICCV, ECCV, NeurIPS, IROS and ICRA. 
                 He serves as a regular reviewer member for a variety of conferences and journals.
              </p>
              <p> <font color="red"> I am looking for self-motivated PhD/Postdoc/Master/research assistant. If you are interested in joining our lab, please drop me an email at ziwei.wang@ntu.edu.sg with your CV.  </font>
              </p>
              <p style="text-align:center">
                <a href="mailto:ziwei.wang@ntu.edu.sg">Email</a> &nbsp/&nbsp
                <a href="data/Resume.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=cMTW09EAAAAJ&hl=en&authuser=1">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/ZiweiWangTHU">Github</a> &nbsp/&nbsp
                <a href="https://x.com/ZiweiWangNTU">Twitter</a>&nbsp/&nbsp
                <a href="https://www.zhihu.com/people/wei-wei-wei-84-43-27?utm_source=article-pc-editor">Zhihu</a>
              </p>
            </td>
            <td style="padding:2.5%;width:30%;max-width:30%">
              <a href="images/Picture 1.jpg"><img style="width:50%;max-width:50%" alt="profile photo" src="images/Picture 1.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
              <p>
                <li style="margin: 5px;" >
                <b>2025-08:</b> I am invited to give a talk in <a href="https://www.panlogin.com"> The 2nd Workshop and Competition on Multi-Robot Perception and Navigation Challenges in Logistics and Inspection Tasks</a> at IROS 2025</a>.
                <li style="margin: 5px;" >
                <b>2025-08:</b> Four papers are accepetd to <a href="https://www.corl.org">CoRL 2025</a>.
                <li style="margin: 5px;" >
                <b>2025-06:</b> Three papers are accepetd to <a href="https://iccv.thecvf.com">ICCV 2025</a>.
                <li style="margin: 5px;" >
                <b>2025-06:</b> Three papers are accepetd to <a href="https://www.iros25.org">IROS 2025</a>.
                <li style="margin: 5px;" >
                <b>2025-02:</b> Four papers are accepetd to <a href="https://cvpr.thecvf.com">CVPR 2025 (<font color="red">1 Highlight paper</font>)</a>.
                <li style="margin: 5px;" >
                <b>2025-01:</b> Two papers are accepetd to <a href="https://iclr.cc">ICLR 2025</a> (<font color="red">1 Oral paper</font>).
                <li style="margin: 5px;" >
                <b>2024-12:</b> I will co-organize the <a href="https://genbot-workshop.github.io"> Generative Models for Robot Learning Workshop</a> at ICLR 2025</a>.
                <li style="margin: 5px;" >
                <b>2024-11:</b> I am invited to give a talk in <a href="https://sites.google.com/view/dai24-embodiedai/">Embodied AI Workshop</a> at DAI 2024</a>.
                <li style="margin: 5px;" >
                <b>2024-09:</b> I am invited to give a talk in <a href="https://venue-tutorial.github.io">Recent Advances in Video Content Understanding and Generation Tutorial</a> at ECCV 2024</a>.
                <li style="margin: 5px;" >
                <b>2024-09:</b> One paper is accepted to <a href="https://neurips.cc">NeurIPS 2024</a>.
                </p>
            </td>
          </tr>
        </tbody></table>



      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Recent Works</heading>
            </td>
          </tr>
        </tbody>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
               <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/VLA-RL.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>VLA-RL: Towards Masterful and General Robotic Manipulation with Scalable Reinforcement Learning</papertitle>
              <br>
              Guanxing Lu, Wenkai Guo, Chubin Zhang, Yuheng Zhou, Haonan Jiang, Zifeng Gao, Yansong Tang, <strong>Ziwei Wang</strong>
              <br>
              <em>Arxiv</em>, 2025
              <br>
              <a href="https://arxiv.org/pdf/2505.18719?">[PDF]</a>
              <a href="https://github.com/GuanxingLu/vlarl">[Code]</a>
              <br>
              </td>
          </tr> 

        </tbody></table>
       

                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Selected Publications</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <br>
              * means equal contribution
          <br>

        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/SafeBimanual.gif" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>SafeBimanual: Diffusion-based Trajectory Optimization for Safe Bimanual Manipulation</papertitle>
              <br>
              Haoyuan Deng, Wenkai Guo, Qianzhun Wang, Zhenyu Wu, <strong>Ziwei Wang</strong>
              <br>
              <em>9th Conference on Robot Learning (<strong>CoRL</strong>)</em>, 2025.
              <br>
              <a href="https://arxiv.org/pdf/2508.18268">[PDF]</a>
              <a href="https://denghaoyuan123.github.io/SafeBimanip/">[Website]</a>
              <br>
              </td>
          </tr> 

            <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/Moto.gif" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>MoTo: A Zero-shot Plug-in Interaction-aware Navigation for General Mobile Manipulation</papertitle>
              <br>
              Zhenyu Wu, Angyuan Ma, Xiuwei Xu, Hang Yin, Yinan Liang, <strong>Ziwei Wang</strong>, Jiwen Lu, Haibin Yan
              <br>
              <em>9th Conference on Robot Learning (<strong>CoRL</strong>)</em>, 2025.
              <br>
              <a href="https://www.arxiv.org/pdf/2509.01658">[PDF]</a>
              <a href="https://gary3410.github.io/MoTo/">[Website]</a>
              <a href="https://www.youtube.com/watch?v=cfy1gF_nk48&t=3s">[Video]</a>
              <br>
              </td>
          </tr> 

          
         <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/AnyBimanual.gif" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Anybimanual: Transferring Unimanual Policy for General Bimanual Manipulation</papertitle>
              <br>
              Guanxing Lu*, Tengbo Yu*, Haoyuan Deng, Season Si Chen, Yansong Tang, <strong>Ziwei Wang</strong>
              <br>
              <em>IEEE International Conference on Computer Vision (<strong>ICCV</strong>)</em>, 2025.
              <br>
              <a href="https://arxiv.org/pdf/2412.06779?">[PDF]</a>
              <a href="https://anybimanual.github.io">[Website]</a>
              <a href="https://www.youtube.com/watch?v=RFwLgtzrXuM">[Video]</a>
              <a href="https://github.com/Tengbo-Yu/AnyBimanual">[Code]</a>
              <br>
              </td>
          </tr>

         <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/GWM.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>GWM: Towards Scalable Gaussian World Models for Robotic Manipulation</papertitle>
              <br>
              Guanxing Lu*, Baoxiong Jia*, Puhao Li*, Yixin Chen, <strong>Ziwei Wang</strong>, Yansong Tang, Siyuan Huang
              <br>
              <em>IEEE International Conference on Computer Vision (<strong>ICCV</strong>)</em>, 2025.
              <br>
              <a href="https://arxiv.org/pdf/2508.17600">[PDF]</a>
              <a href="https://gaussian-world-model.github.io">[Website]</a>
              [Code (Coming Soon)]
              <br>
              </td>
          </tr>


        <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/ManiGaussian++.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>ManiGaussian++: General Robotic Bimanual Manipulation with Hierarchical Gaussian World Model</papertitle>
              <br>
              Tengbo Yu*, Guanxing Lu*, Zaijia Yang*, Haoyuan Deng, Season Si Chen, Jiwen Lu, Wenbo Ding, Guoqiang Hu, Yansong Tang, <strong>Ziwei Wang</strong>
              <br>
              <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (<strong>IROS</strong>)</em>, 2025.
              <br>
              <a href="https://arxiv.org/pdf/2506.19842">[PDF]</a>
              <a href="https://github.com/April-Yz/ManiGaussian_Bimanual">[Code]</a>
              <br>
              </td>
          </tr>

        <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/Tapa.gif" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Embodied Instruction Following in Unknown Environments</papertitle>
              <br>
              Zhenyu Wu, <strong>Ziwei Wang</strong>, Xiuwei Xu, Jiwen Lu, Haibin Yan
              <br>
              <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (<strong>IROS</strong>)</em>, 2025.
              <br>
              <a href="https://arxiv.org/pdf/2406.11818">[PDF]</a>
              <a href="https://gary3410.github.io/eif_unknown/">[Website]</a>
              <a href="https://github.com/Gary3410/eif_unknown">[Code]</a>
              <br>
              </td>
          </tr>

         <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/MoManipVLA.gif" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>MoManipVLA: Transferring Vision-language-action Models for General Mobile Manipulation</papertitle>
              <br>
              Zhenyu Wu, Yuheng Zhou, Xiuwei Xu, <strong>Ziwei Wang</strong>, Haibin Yan
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2025.
              <br>
              <a href="https://arxiv.org/pdf/2503.13446">[PDF]</a>
              <a href="https://gary3410.github.io/momanipVLA/">[Website]</a>
              <br>
        </td>
          </tr> 

         <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/Unigoal.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>UniGoal: Towards Universal Zero-shot Goal-oriented Navigation</papertitle>
              <br>
              Hang Yin*, Xiuwei Xu*, Linqing Zhao, <strong>Ziwei Wang</strong>, Jie Zhou, Jiwen Lu
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2025.
              <br>
              <a href="https://arxiv.org/pdf/2503.10630">[PDF]</a>
              <a href="https://bagh2178.github.io/UniGoal/">[Code]</a>
              <br>
              </td>
          </tr> 

        <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/TSP3D.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Text-guided Sparse Voxel Pruning for Efficient 3D Visual Grounding</papertitle>
              <br>
              Wenxuan Guo*, Xiuwei Xu*, <strong>Ziwei Wang</strong>, Jianjiang Feng, Jie Zhou, Jiwen Lu
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>, <font color="red"><strong>Highlight</strong></font>)</em>, 2025.
              <br>
              <a href="https://arxiv.org/pdf/2502.10392v1">[PDF]</a>
              <a href="https://github.com/GWxuan/TSP3D">[Code]</a>
              <a href="https://zhuanlan.zhihu.com/p/29557016028">[中文解读]</a>
              <br>
              </td>
          </tr> 

          
         <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/ThinkBot.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>ThinkBot: Embodied Instruction Following with Thought Chain Reasoning</papertitle>
              <br>
              Guanxing Lu, <strong>Ziwei Wang</strong>, Changliu Liu, Jiwen Lu, Yansong Tang
              <br>
              <em>The Thirteenth International Conference on Learning Representations (<strong>ICLR</strong>)</em>, 2025
              <br>
              <a href="https://arxiv.org/pdf/2312.07062">[PDF]</a>
              <a href="https://guanxinglu.github.io/thinkbot/">[Website]</a>
              <a href="images/ThinkBot_demo.mp4">[Video]</a>
              <br>
              </td>
          </tr> 
          
               <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/EmbodiedSAM.gif" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>EmbodiedSAM: Online Segment Any 3D Thing in Real Time</papertitle>
              <br>
              Xiuwei Xu, Huangxing Chen, Linqing Zhao, <strong>Ziwei Wang</strong>, Jie Zhou, Jiwen Lu
              <br>
              <em>The Thirteenth International Conference on Learning Representations (<strong>ICLR</strong>, <font color="red"><strong>Oral</strong></font>)</em>, 2025
              <br>
              <a href="https://arxiv.org/pdf/2408.11811">[PDF]</a>
              <a href="https://xuxw98.github.io/ESAM/">[Website]</a>
              <a href="https://github.com/xuxw98/ESAM">[Code]</a>
              <a href="https://cloud.tsinghua.edu.cn/f/f75279f89bf64720b8ec/?dl=1">[Video]</a>
              <br>
              </td>
          </tr> 


          
               <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/Q-VLM.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Q-VLM: Post-training Quantization for Large Vision-Language Models</papertitle>
              <br>
              Changyuan Wang, <strong>Ziwei Wang</strong>, Xiuwei Xu, Yansong Tang, Jie Zhou, Jiwen Lu 
              <br>
              <em>Thirty-eighth Conference on Neural Information Processing Systems (<strong>NeurIPS</strong>)</em>, 2024.
              <br>
              <a href="data/Q-VLM.pdf">[PDF]</a>
              <a href="data/Q-VLM_supp.pdf">[Supp]</a>
              <a href="https://github.com/ChangyuanWang17/QVLM">[Code]</a>
              <br>
              </td>
          </tr>
          
               <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/ManiGaussian.gif" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>ManiGaussian: Dynamic Gaussian Splatting for Multi-task Robotic Manipulation</papertitle>
              <br>
              Guanxing Lu, Shiyi Zhang, <strong>Ziwei Wang</strong><sup>&dagger;</sup>, Changliu Liu, Jiwen Lu, Yansong Tang
              <br>
              <em>European Conference on Computer Vision (<strong>ECCV</strong>)</em>, 2024
              <br>
              <a href="https://arxiv.org/abs/2403.08321">[PDF]</a>
              <a href="https://github.com/GuanxingLu/ManiGaussian">[Code]</a>
              <a href="https://guanxinglu.github.io/ManiGaussian/">[Website]</a>
              <br>
              </td>
          </tr>

               <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/DSP3D.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>3D Small Object Detection with Dynamic Spatial Pruning</papertitle>
              <br>
             Xiuwei Xu*, Zhihao Sun*, <strong>Ziwei Wang</strong>, Hongming Liu, Jie Zhou, Jiwen Lu
              <br>
              <em>European Conference on Computer Vision (<strong>ECCV</strong>)</em>, 2024
              <br>
              <a href="https://arxiv.org/abs/2305.03716">[PDF]</a>
              <a href="https://github.com/xuxw98/DSPDet3D">[Code]</a>
              <a href="https://xuxw98.github.io/DSPDet3D/">[Website]</a>
              <br>
              </td>
          </tr>

        <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/StableLego.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>StableLego: Stability Analysis of Block Stacking Assembly</papertitle>
              <br>
              Ruixuan Liu, Kangle Deng, <strong>Ziwei Wang</strong>, Changliu Liu
              <br>
              <em>IEEE Robotics and Automation Letters (<strong>RAL</strong>)</em>, 2024
              <br>
              <a href="data/StableLego.pdf">[PDF]</a>
              <a href="https://github.com/intelligent-control-lab/StableLego">[Code and Dataset]</a>
              <br>
              <p></p>
            </td>
          </tr>


          <!--
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/R-GMPQ.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Learning Generalizable Mixed-Precision Quantization via Attribution Imitation</papertitle>
              <br>
              <strong>Ziwei Wang</strong>, Han Xiao, Jie Zhou, Jiwen Lu
              <br>
              <em>International Journal of Computer Vision (<strong>IJCV</strong>)</em>, 2024.
              <br>
              <a href="data/R-GMPQ.pdf">[PDF]</a>
              <a href="https://github.com/ZiweiWangTHU/GMPQ">[Code]</a>
              <br>
              </td>
          </tr>


          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/APQ-DM.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Towards Accurate Data-free Quantization for Diffusion Models</papertitle>
              <br>
              Changyuan Wang, <strong>Ziwei Wang</strong>, Xiuwei Xu, Yansong Tang, Jie Zhou, Jiwen Lu
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>, <font color="red"><strong>Highlight</strong></font>)</em>, 2024.
              <br>
              <a href="data/APQ-DM.pdf">[PDF]</a>
              <a href="data/APQ-DM-supp_supp.pdf">[Supp]</a>
              <a href="https://github.com/ChangyuanWang17/APQ-DM">[Code]</a>
              <br>
              </td>
          </tr>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/Online-3D.mp4' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Memory-based Adapters for Online 3D Scene Perception</papertitle>
              <br>
              Xiuwei Xu*, Chong Xia*, <strong>Ziwei Wang</strong>, Linqing Zhao, Yueqi Duan, Jie Zhou, Jiwen Lu
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2024.
              <br>
              <a href="data/Onine-3D.pdf">[PDF]</a>
              <a href="https://github.com/xuxw98/Online3D">[Code]</a>
              <a href="https://xuxw98.github.io/Online3D/">[Website]</a>
              <br>
              </td>
          </tr>
          
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/MCUFormer.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>MCUFormer: Deploying Vision Transformers on Microcontrollers with Limited Memory</papertitle>
              <br>
              Yinan Liang, <strong>Ziwei Wang</strong>, Xiuwei Xu, Yansong Tang, Jie Zhou, Jiwen Lu
              <br>
              <em>Thirty-seventh Conference on Neural Information Processing Systems (<strong>NeurIPS</strong>)</em>, 2023.
              <br>
              <a href="data/MCUFormer.pdf">[PDF]</a>
              <a href="data/MCUFormer_supp.pdf">[Supp]</a>
              <a href="https://github.com/liangyn22/MCUFormer">[Code]</a>
              <br>
              </td>
          </tr>
          
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/SeerNet.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Learning Accurate Performance Predictors for Ultrafast Automated Model Compression</papertitle>
              <br>
              <strong>Ziwei Wang</strong>, Jiwen Lu, Han Xiao, Shengyu Liu, Jie Zhou
              <br>
              <em>International Journal of Computer Vision (<strong>IJCV</strong>)</em>, 2023.
              <br>
              <a href="data/SeerNet.pdf">[PDF]</a>
              <a href="https://github.com/ZiweiWangTHU/SeerNet">[Code]</a>
              <br>
              </td>
          </tr>
          
          
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/ICRA23.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Category-level Shape Estimation for Densely Cluttered Objects</papertitle>
              <br>
              Zhenyu Wu, <strong>Ziwei Wang</strong>, Jiwen Lu, Haibin Yan
              <br>
              <em>IEEE International Conference on Robotics and Automation (<strong>ICRA</strong>)</em>, 2023.
              <br>
              <a href="data/ICRA2023.pdf">[PDF]</a>
              <a href="https://github.com/Gary3410/Shape-Estimation">[Code]</a>
              <br>
              </td>
          </tr>
          
          
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/Quantformer.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Quantformer: Learning Extremely Low-precision Vision Transformers</papertitle>
              <br>
              <strong>Ziwei Wang</strong>, Changyuan Wang, Xiuwei Xu, Jie Zhou, Jiwen Lu
              <br>
              <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>T-PAMI</strong>)</em>, 2022.
              <br>
              <a href="data/Quantformer.pdf">[PDF]</a>
              <a href="data/Quantformer-supp.pdf">[Supp]</a>
              <a href="https://github.com/ZiweiWangTHU/Quantformer">[Code]</a>
              <br>
              </td>
          </tr>
          
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/PackingPlanning.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Planning Irregular Object Packing via Hierarchical Reinforcement Learning</papertitle>
              <br>
              Sichao Huang, <strong>Ziwei Wang</strong>, Jie Zhou, Jiwen Lu
              <br>
              <em>IEEE Robotics and Automation Letters (<strong>RAL</strong>)</em>, 2022
              <br>
              <a href="data/PackingPlanning.pdf">[PDF]</a>
              <a href="https://github.com/Chiba9/Irregular-Object-Packing/blob/main/video_demo/demo_robot.mp4">[Robot Demo]</a>
              <a href="https://github.com/Chiba9/Irregular-Object-Packing/blob/main/video_demo/demo_simulation.mp4">[Simulation Demo]</a>
              <a href="https://github.com/Chiba9/Irregular-Object-Packing">[Code]</a>
              <br>
              <p></p>
              </td>
          </tr>
          
          
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/Fig_Smart Explorer.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Smart Explorer: Recognizing Objects in Dense Clutter via Interactive Exploration</papertitle>
              <br>
              Zhenyu Wu*, <strong>Ziwei Wang*</strong>, Zibu Wei, Yi Wei, Haibin Yan
              <br>
              <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (<strong>IROS</strong>)</em>, 2022.
              <br>
              <a href="data/Smart Explorer.pdf">[PDF]</a>
              <a href="data/IROS22_0255_VI_fi.mp4">[Demo]</a>
              <a href="https://github.com/Gary3410/Smart-Explorer">[Code]</a>
              <br>
              <p></p>
              </td>
          </tr>
          
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/Fig_GE-Grasp.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>GE-Grasp: Efficeint Target Oriented Grasping in Dense Clutter</papertitle>
              <br>
              Zhan Liu, <strong>Ziwei Wang</strong>, Sichao Huang, Jie Zhou, Jiwen Lu
              <br>
              <em>IEEE/RSJ International Conference on Intelligent Robots and Systems (<strong>IROS</strong>)</em>, 2022.
              <br>
              <a href="data/GE-Grasp.pdf">[PDF]</a>
              <a href="data/IROS22_0216_VI_fi.mp4">[Demo]</a>
              <a href="https://github.com/CaptainWuDaoKou/GE-Grasp">[Code]</a>
              <br>
              <p></p>
              </td>
          </tr>     
          
           <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/Shapley-NAS.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Shapley-NAS: Discovering Operation Contribution for Neural Architecture Search</papertitle>
              <br>
              Han Xiao, <strong>Ziwei Wang</strong>, Zheng Zhu, Jie Zhou, Jiwen Lu
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2022.
              <br>
              <a href="data/04143.pdf">[PDF]</a>
              <a href="data/04143-supp.pdf">[Supplement]</a>
              <a href="https://github.com/Euphoria16/Shapley-NAS">[Code]</a>
              <br>
              <p></p>
              </td>
          </tr>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/AutoBiDet_Pipeline.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Learning Efficient Binarized Object Detectors with Information Compression</papertitle>
              <br>
              <strong>Ziwei Wang</strong>, Jiwen Lu, Ziyi Wu, Jie Zhou
              <br>
              <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>T-PAMI</strong>)</em>, 2022.
              <br>
              <a href="data/AutoBiDet.pdf">[PDF]</a>
              <a href="data/AutoBiDet-supp.pdf">[Supplement]</a>
              <a href="https://github.com/ZiweiWangTHU/BiDet">[Code]</a>
              <br>
              <p></p>
              </td>
          </tr>
          
           <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/GMPQ.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Generalizable Mixed-Precision Quantization via Attribution Rank Preservation</papertitle>
              <br>
              <strong>Ziwei Wang</strong>, Han Xiao, Jiwen Lu, Jie Zhou
              <br>
              <em>IEEE International Conference on Computer Vision (<strong>ICCV</strong>)</em>, 2021.
              <br>
              <a href="data/02669.pdf">[PDF]</a>
              <a href="data/02669-supp.pdf">[Supplement]</a>
              <a href="https://github.com/ZiweiWangTHU/GMPQ">[Code]</a>
              <br>
              <p></p>
              </td>
          </tr>
          
          
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/BiDet.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>BiDet: An Efficient Binarized Object Detector</papertitle>
              <br>
              <strong>Ziwei Wang</strong>, Ziyi Wu, Jiwen Lu, Jie Zhou
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2020
              <br>
              <a href="data/05105.pdf">[PDF]</a> <a href="https://github.com/ZiweiWangTHU/BiDet">[Code]</a>
              <br>
              <p></p>
              </td>
          </tr>

          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/CI-BCNN.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Learning Channel-wise Interactions for Binary Convolutional Neural Networks</papertitle>
              <br>
              <strong>Ziwei Wang</strong>, Jiwen Lu, Chenxin Tao, Jie Zhou
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2019
              <br>
              <a href="data/1279.pdf">[PDF]</a> <a href="https://github.com/ZiweiWangTHU/CI-BCNN">[Code]</a> 
              <br>
              </td>
          </tr>
          -->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Honors and Awards</heading>
              <p>
                <li style="margin: 5px;"> 2024 Outstanding Doctoral Dissertation of Beijing</li>
                <li style="margin: 5px;"> 2023 Outstanding Doctoral Dissertation of Tsinghua University</li>
                <li style="margin: 5px;"> 2022 National Scholarship</li>
                <li style="margin: 5px;"> 2020 National Scholarship</li>
                <li style="margin: 5px;"> 2018 Chi-Sun Yeh Scholarship </li>
                <li style="margin: 5px;"> 2016 Qualcomm Scholarship</li>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Academic Services</heading>
            <p>
              <li style="margin: 5px;"> 
                <b>Conference Reviewer:</b> CVPR, ICCV, ECCV, NeurIPS, ICML, ICLR, ICRA, IROS, CoRL
              </li>
              <li style="margin: 5px;"> 
                <b>Journal Reviewer:</b>  T-PAMI, T-IP, T-CSVT, T-NNLS, T-IV, R-AL, Pattern Recognition, Journal of Field Robotics
              </li>
            </p>
          </td>
        </tr>
      </tbody></table>

      <p><center>
        <div id="clustrmaps-widget" style="width:30%">
            <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=NqC5MQ-GbQ-5lz4PMAXHVUYxsOQKDgFySz02VlxH-t4"></script></div>
        <br>
        &copy; Ziwei Wang | Last update: July. 2, 2024
    </center></p >
       
  
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <a href="https://jonbarron.info/">Website Template</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
